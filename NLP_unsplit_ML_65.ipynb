{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef14ad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependecies \n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import contractions\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures, TrigramCollocationFinder\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7aa40-5f22-4deb-a53e-6ecc09e9cab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mbti_1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd96853",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = df.type.unique()\n",
    "print(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.barplot(label_counts.index, label_counts.values)\n",
    "plt.ylabel('Counts')\n",
    "plt.xlabel('Personality Types')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccee63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, column_name = \"posts\", new_column=\"cleaned_post\"):\n",
    "    df[new_column] = df[column_name].apply(lambda x: contractions.fix(x))\n",
    "    df[new_column] = df[new_column].apply(lambda x: x.lower())\n",
    "    df[new_column] = df[new_column].apply(lambda x: re.sub(r'@([a-zA-Z0-9_]{1,50})', '', x))\n",
    "    df[new_column] = df[new_column].apply(lambda x: re.sub(r'#([a-zA-Z0-9_]{1,50})', '', x))\n",
    "    df[new_column] = df[new_column].apply(lambda x: re.sub(r'http[s]?://\\S+', '', x))\n",
    "    df[new_column]= df[new_column].apply(lambda x: re.sub(r'[^A-Za-z]+', ' ', x))\n",
    "    df[new_column] = df[new_column].apply(lambda x: re.sub(r' +', ' ', x))\n",
    "    df[new_column] = df[new_column].apply(lambda x: \" \".join([word for word in x.split() if not len(word) <3]))\n",
    "    return df\n",
    "\n",
    "cleaned_df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df[\"words_count\"] = cleaned_df[\"cleaned_post\"].apply(lambda x: len(x.split()))\n",
    "cleaned_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.swarmplot(\"type\", \"words_count\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3524467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent(data, stopword, column=\"cleaned_post\", top=25):\n",
    "    df = data[column].apply(lambda x: \" \".join([word for word in x.split() if not word in stopword]))\n",
    "    counter = Counter(\" \".join(df).split())\n",
    "    return counter.most_common(top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1157b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequents = get_most_frequent(cleaned_df, stopword)\n",
    "most_frequents[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_df = pd.DataFrame(most_frequents)   \n",
    "plt.figure(figsize=(20,5))\n",
    "sns.barplot(most_frequent_df.iloc[:20, 0], most_frequent_df.iloc[:20, 1])\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Top Frequent Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(cleaned_df['type'].unique()), sharex=True, figsize=(5,5*len(cleaned_df['type'].unique())))\n",
    "\n",
    "k = 0\n",
    "for i in cleaned_df['type'].unique():\n",
    "    df = cleaned_df[cleaned_df['type'] == i]\n",
    "    wordcloud = WordCloud().generate(df['cleaned_post'].to_string())\n",
    "    ax[k].imshow(wordcloud)\n",
    "    ax[k].set_title(i)\n",
    "    ax[k].axis(\"off\")\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686918e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(data, n_gram, new_column, column=\"cleaned_post\"):\n",
    "    data[\"tokenized\"]  = data[column].apply(lambda x: x.split())\n",
    "    data[\"sw_removal\"] = data[\"tokenized\"].apply(lambda x: [y for y in x if not y in stopword])\n",
    "    data[new_column]   = data[\"sw_removal\"].apply(lambda x: list(ngrams(x, n_gram)))\n",
    "    data.drop(columns  = [\"tokenized\", \"sw_removal\"], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa6527",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_ngrams(cleaned_df, n_gram=2, new_column=\"bigrams\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_ngrams(data, n_gram=3, new_column=\"trigrams\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_df[\"cleaned_post\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(cleaned_df['type'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d59051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3196656",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6f1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f35417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b3836",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63758dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = pd.DataFrame(X_test.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tf_idf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95acfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    nb_clf  = MultinomialNB(alpha=0.01)\n",
    "    svm_clf = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    dt_clf  = DecisionTreeClassifier(max_depth=7)\n",
    "    rf_clf  = RandomForestClassifier(n_estimators=750)\n",
    "    xgb_clf = xgboost.XGBClassifier(use_label_encoder=False)\n",
    "    return {\"NaiveBayes\":nb_clf, \"SVM\":svm_clf, \"DecisionTree\":dt_clf, \"RandomForest\":rf_clf, \"Xgboost\":xgb_clf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_metrics = [\"Accuracy\"]\n",
    "_columns = [\"NaiveBayes\", \"SVM\", \"DecisionTree\", \"RandomForest\", \"Xgboost\"]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99248ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = pd.DataFrame(columns=_columns, index=[_metrics])\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3845d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = create_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_predict)\n",
    "print(classification_report(y_test, y_predict))\n",
    "n_right = 0 \n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == y_test[i]:\n",
    "        n_right+=1\n",
    "print(\"Accuracy: %.2f%%\"%((n_right/float(len(y_test))*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=1.0, kernel='linear', degree=3, gamma='auto').fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_predict)\n",
    "print(classification_report(y_test, y_predict))\n",
    "n_right = 0 \n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == y_test[i]:\n",
    "        n_right+=1\n",
    "print(\"Accuracy: %.2f%%\"%((n_right/float(len(y_test))*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=750).fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_predict)\n",
    "print(classification_report(y_test, y_predict))\n",
    "n_right = 0 \n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == y_test[i]:\n",
    "        n_right+=1\n",
    "print(\"Accuracy: %.2f%%\"%((n_right/float(len(y_test))*100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0261ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgboost.XGBClassifier().fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_predict)\n",
    "print(classification_report(y_test, y_predict))\n",
    "n_right = 0 \n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == y_test[i]:\n",
    "        n_right+=1\n",
    "print(\"Accuracy: %.2f%%\"%((n_right/float(len(y_test))*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbb761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "print(f\"Training score: {clf.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eaa045",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9108e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_right = 0 \n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == y_test[i]:\n",
    "        n_right+=1\n",
    "print(\"Accuracy: %.2f%%\"%((n_right/float(len(y_test))*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695efc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450bfe7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204da9a-ac5c-4b8f-8bc6-83990ab41449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
